{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a37cc69",
   "metadata": {},
   "source": [
    "# Privacy Preserving Machine Learning Practical Session 1\n",
    "\n",
    "Practical Session adapted from the Course of Olivier Cappé \n",
    "\n",
    "Course page: https://www.di.ens.fr/olivier.cappe/Courses/IASD-DP/\n",
    "\n",
    "<div style=\"text-align: right\"> \n",
    "Sorbonne Université, MS2A, Master 2\n",
    "</div>\n",
    "\n",
    "## Goal of the practical session \n",
    "\n",
    "The objective of this practical session is to introduce methods often regarded as privacy-preserving within parts of the data processing community. While these approaches are widely used as \"best efforts\" for privacy, they come with significant failure modes that must be understood. Exploring these concepts and their vulnerabilities is essential before advancing to more robust privacy solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51474d83-2ec8-402d-beb3-e6ddc95cab85",
   "metadata": {
    "id": "51474d83-2ec8-402d-beb3-e6ddc95cab85"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import matplotlib.pylab as pl\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db913f49-7ddf-486a-9247-da73819620df",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "1. [Part 1: K-Anonymity + L-Diversity + T-Closeness](#part1)\n",
    "    - [Presenting K-anonymity](#part1sec1)\n",
    "        - [Question 1 (span and split functions)](#part1sec2)\n",
    "        - [Question 2 (Implementing the Mondrian partitionning algorithm)](#part1sec3)\n",
    "        - [Question 3 (Analyzing the partition)](#part1sec4)\n",
    "        - [Question 4 (Limitations of k-anonimity)](#part1sec5)\n",
    "    - [Presenting L-diversity (naive way)](#part1sec6)\n",
    "        - [Question 5 (Implementing l-diversity)](#part1sec7)\n",
    "        - [Question 6 (Limitations of l-diversity)](#part1sec8)\n",
    "    - [Presenting T-closeness](#part1sec9)\n",
    "        - [Question 7 (Implementing t-closeness)](#part1sec10)\n",
    "        - [Question 8 (Analysis of the usefulness of t-closeness)](#part1sec11)\n",
    "1. [Part 2: Brittlness of privacy through aggregation (a.k.a. attacking ML models)](#part2)\n",
    "    - [Question 1 (Warm-Up: guessing the target vetcore from aggregated observations)](#part2sec1)\n",
    "    - [Question 2 (Warm-Up: verifying the attack)](#part2sec2)\n",
    "    - [Question 3 (Model inversion attack on a logstic regression)](#part2sec3)\n",
    "    - [Question 4 (Success with respect to side information)](#part2sec4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839e06e0-3560-4e07-a4e6-ff6978b8bd9b",
   "metadata": {},
   "source": [
    "# Part 1: K-anonymity, L-diversity, T-closeness and their limitations <a id=\"part1\"></a>\n",
    "\n",
    "In the late 1990s Sweeney published several articles in which she proposed the concept of k-anonymity. Among them we cite the most famous one [1] published in 2002. At the time when anonymization was referring to the concept now known as pseudonymization. Pseudonymization is the replacement of all directly identifying data (such as the social security number) with a random value (pseudonym). As we mentioned during the first lecture, Sweeney showed in [1] that it was possible to re-identify a pseudonymized relational database (SQL or more generally a tabular file) and proposed a simple notion called \"k-anonimity\" to prevent these kind of leak from hapenning.\n",
    "\n",
    "## Presenting K-anonymity <a id=\"part1sec\"></a>\n",
    "\n",
    "Suppose we have a dataset $D$ containing $n$ entries. Each entry in $D$ consists of a set of attributes—such as age, gender, and zip code—that are non-sensitive on their own but can act as quasi-identifiers. When combined, these attributes form a \"super-identifier\" that may uniquely identify an individual, even in large datasets (e.g., the combination of gender, age, and zip code might be unique to a single person; see [1] for further details). Additionally, let us assume the dataset includes a single sensitive attribute (such as income) that we aim to protect. While $k$-anonimity can be generalized to datasets with multiple sensitive attributes or those lacking a clear distinction between quasi-identifiers and sensitive attributes, we will focus on this simplified case for this practical session.\n",
    "\n",
    "The concept of $k$-Anonymity protects individual privacy by grouping records into clusters of at least $k$ individuals. In essence, a dataset satisfies $k$-anonymity if every entry shares its quasi-identifiers with at least $k-1$ other entries. To achieve this, the dataset is partitioned into groups of at least $k$ records, and the quasi-identifiers within each group are replaced with aggregated values. This aims to ensure that an adversary, even with full knowledge of a person’s quasi-identifiers, can only infer the group to which the person might belong and not whether the person is actually in the dataset.\n",
    "\n",
    "**Implementing k-anonimity:** Turning a dataset into a $k$-anonymous dataset is a complex problem. Meyerson and Williams have shown in [2] that finding the optimal $k$-anonymous transformation of the database is NP-difficult. Fortunately, several practical algorithms exists that often produce \"good enough\" results by employing greedy search techniques. In this notebook, we will explore the so-called \"Mondrian\" (see [3] for more details) algorithm, which uses a greedy search method to partition the original data into smaller and smaller groups. The algorithm assumes that we have converted all attributes into numerical or categorical values and that we are able to measure the \"span\" of a given data attribute (\"span\" will be detailed later). The algorithm proceeds then as follows to partition the data into $k$ groups:\n",
    "\n",
    "1. Initialize the final set of partitions to an empty set $P_{final} = \\{\\}$.\n",
    "2. Initialize the temporary set of paritions to a set containing a partition with the entire dataset $P_{temp} = \\{\\{1, 2,\\dots ,n\\}\\}$.\n",
    "4. While there are partitions in the temporary set, pop out one partition from it.\n",
    "  * Compute the relative spans of all columns in the partition.\n",
    "  * Sort the resulting columns by their span (in descending order) and iterate over them. For each column,\n",
    "      * Try to split the partition along that column using the median of the column values as the split point.\n",
    "      * Check if the resulting partitions are valid according to k-anonymity (and possibly additional) criteria.\n",
    "      * If yes, add the two new partitions to the temporary set and break out of the loop.\n",
    "  * If no column produced a valid split, add the original partition to the set of final partitions.\n",
    "5. Return the final set of partitions\n",
    "\n",
    "After obtaining the partitions we still need to aggregate the values of the quasi identifiers and the sensitive attributes in each $k$-anonymous group. For this, we can e.g. replace numerical attributes with their range (e.g. \"age: 24-28\") and categorical attributes with their union (e.g. \"employment-group: [self-employed, employee, worker]\"), though other aggregations are possible. An open source tool developed by the Technological University of Munich, ARX (see [4]) allows anonymisation according to many models from original data in tabular format. The tool also makes it possible to estimate the risks of de-anonymization according to the models presented above, and even in a finer way by calculating the distribution of the probabilities of de-anonymization and not simply the maximum values.\n",
    "\n",
    "- [1] [k-Anonymity: A Model For Protecting Privacy](https://epic.org/privacy/reidentification/Sweeney_Article.pdf)\n",
    "- [2] [On the Complexity of Optimal K-Anonymity](http://www.aladdin.cs.cmu.edu/papers/pdfs/y2004/kanonim.pdf)\n",
    "- [3] [Mondrian - Multidimensional k-Anonymity](https://www.utdallas.edu/~muratk/courses/privacy08f_files/MultiDim.pdf)\n",
    "- [4] [Putting statistical disclosure control into practice: The ARX data anonymization tool](https://link.springer.com/chapter/10.1007/978-3-319-23633-9_6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7402898a-6337-4a58-b6ab-9a9ed782d43e",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "We will be working with a dataset from the US Census (also known as the Adult dataset). You can read about the dataset [here](https://archive.ics.uci.edu/ml/datasets/census+income). The following line loads the dataset from a text file in `pandas DataFrame` format: this keeps the attributes in their original form and will be more convenient to work with. If you prefer working with a numpy array, set `as_frame=False` but it is not recommended in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e430ce03-091f-4a58-8622-2d732e5217d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = (\n",
    "    'age',\n",
    "    'workclass',\n",
    "    'fnlwgt',\n",
    "    'education',\n",
    "    'education-num',\n",
    "    'marital-status',\n",
    "    'occupation',\n",
    "    'relationship',\n",
    "    'race',\n",
    "    'sex',\n",
    "    'capital-gain',\n",
    "    'capital-loss',\n",
    "    'hours-per-week',\n",
    "    'native-country',\n",
    "    'income',\n",
    ")\n",
    "\n",
    "categorical = set((\n",
    "    'workclass',\n",
    "    'education',\n",
    "    'marital-status',\n",
    "    'occupation',\n",
    "    'relationship',\n",
    "    'sex',\n",
    "    'native-country',\n",
    "    'race',\n",
    "    'income',\n",
    "))\n",
    "df = pd.read_csv(\"adult.all.txt\", sep=\", \", header=None, names=names, index_col=False, engine='python');\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d5f6ff-7b96-4cd9-a522-310bc0674eb8",
   "metadata": {},
   "source": [
    "### Question 1 (span and split functions) <a id=\"part1sec2\"></a>\n",
    "\n",
    "Implement a function called ``get_spans`` that computes the spans of all columns for a given partition of a dataframe. For numerical columns, the span is defined as the difference between the maximum and minimum values of the partition, while for categorical columns, it is the count of unique values. Additionally, implement a ``split`` function that divides a dataframe partition into two subsets based on a specified numerical column. The function should return two ensembles: one containing all rows with values below the median of the specified column, and the other containing rows with values equal to or above the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfdcbc1-e43c-435d-8546-2782f1e50601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spans(df, partition, scale=None):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: \n",
    "        The dataframe of reference\n",
    "    partition: \n",
    "        The partition for which to calculate the spans\n",
    "    scale: \n",
    "        If given, the spans of each column will be divided by the value in `scale` for that column\n",
    "    Returns\n",
    "    -------                 \n",
    "    spans: \n",
    "        The spans of all columns in the partition\n",
    "    \"\"\"\n",
    "    # TO COMPLETE\n",
    "    pass # this is just to avoid error while the function is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40a1544-bc8a-490d-909f-f6003a946ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df, partition, column):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: \n",
    "        The dataframe of reference\n",
    "    partition: \n",
    "        The partition to split\n",
    "    column: \n",
    "        The column along which to split\n",
    "    \n",
    "    Returns\n",
    "    ------- \n",
    "    splits: \n",
    "        A tuple containing a split of the original partition\n",
    "    \"\"\"\n",
    "    # TO COMPLETE\n",
    "    pass # this is just to avoid error while the function is empty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216f70be-e35e-4af4-a72b-2f2054b61059",
   "metadata": {},
   "source": [
    "### Question 2 (Implementing the Mondrian partitionning algorithm) <a id=\"part1sec3\"></a>\n",
    "\n",
    "Now that all helper functions are ready, we can proceed to implement the Mondrian algorithm as described. Your task is to develop the partitioning algorithm using a $k$-anonymous criterion for the generated partitions. To achieve this, start by completing the ``is_k_anonymous`` function, which checks whether a newly created partition meets the $k$-anonymity requirement. Once this function is ready, integrate it into the ``partition_dataset`` function, which will generate a $k$-anonymous partition proposal for the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1f3534-d2ea-4eac-822d-4ea5ed2cc5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_k_anonymous(df, partition, sensitive_column, k=3):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: \n",
    "        The dataframe on which to check the partition.\n",
    "    partition: \n",
    "        The partition of the dataframe to check.\n",
    "    sensitive_column: \n",
    "        The name of the sensitive column\n",
    "    k: \n",
    "        The desired k\n",
    "    \n",
    "    Returns\n",
    "    ------- \n",
    "    verif: \n",
    "        True if the partition is valid according to our k-anonymity criteria, False otherwise.\n",
    "    \"\"\"\n",
    "    # TO COMPLETE\n",
    "    pass # this is just to avoid error while the function is empty\n",
    "\n",
    "def partition_dataset(df, feature_columns, sensitive_column, scale, is_valid):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: \n",
    "        The dataframe to be partitioned.\n",
    "    feature_columns: \n",
    "        A list of column names along which to partition the dataset.\n",
    "    sensitive_column: \n",
    "        The name of the sensitive column (to be passed on to the `is_valid` function)\n",
    "    scale: \n",
    "        The column spans as generated before.\n",
    "    is_valid: \n",
    "        A function that takes a dataframe and a partition and returns True if the partition is valid.\n",
    "    \n",
    "    Returns\n",
    "    ------- \n",
    "    valid_part: \n",
    "        A list of valid partitions that cover the entire dataframe.            \n",
    "    \"\"\"\n",
    "    # TO COMPLETE\n",
    "    pass # this is just to avoid error while the function is empty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f78280-3799-4ec9-b08d-401f3685e30d",
   "metadata": {},
   "source": [
    "### Question 3 (Analyzing the partition) <a id=\"part1sec4\"></a>\n",
    "\n",
    "Let's apply this to our dataset. To keep things manageable, we will focus on just two columns for partitioning: 'age' and 'hours of work per week', which will serve as our pseudo-identifiers. Furthermore, we will treat 'income' as the sensitive attribute. After running the partitioning algorithm, we visualize the resulting partitions to better understand how the data is divided.\n",
    "To do this, we run a functions to determine the rectangular bounds of each partition along the two selected columns. By plotting these rectangles, we can see how the partitioning function segments the dataset. If we restrict the partitioning to only these two columns, the resulting rectangles should be non-overlapping and collectively cover the entire dataset. Run the code below and analyze the result we get. What can you say about the way the dataset is partitionned ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ea0c12-9ed1-4557-a196-59576349fe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the partition\n",
    "feature_columns = ['age', 'hours-per-week']\n",
    "sensitive_column = 'income'\n",
    "final_partitions = partition_dataset(df, feature_columns, sensitive_column, full_spans, is_k_anonymous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e9dead-9ce7-4577-9e84-86997e0185b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_indexes(df):\n",
    "    indexes = {}\n",
    "    for column in categorical:\n",
    "        values = sorted(df[column].unique())\n",
    "        indexes[column] = { x : y for x, y in zip(values, range(len(values)))}\n",
    "    return indexes\n",
    "\n",
    "def get_coords(df, column, partition, indexes, offset=0.1):\n",
    "    if column in categorical:\n",
    "        sv = df[column][partition].sort_values()\n",
    "        l, r = indexes[column][sv[sv.index[0]]], indexes[column][sv[sv.index[-1]]]+1.0\n",
    "    else:\n",
    "        sv = df[column][partition].sort_values()\n",
    "        next_value = sv[sv.index[-1]]\n",
    "        larger_values = df[df[column] > next_value][column]\n",
    "        if len(larger_values) > 0:\n",
    "            next_value = larger_values.min()\n",
    "        l = sv[sv.index[0]]\n",
    "        r = next_value\n",
    "    # we add some offset to make the partitions more easily visible\n",
    "    l -= offset\n",
    "    r += offset\n",
    "    return l, r\n",
    "\n",
    "def get_partition_rects(df, partitions, column_x, column_y, indexes, offsets=[0.1, 0.1]):\n",
    "    rects = []\n",
    "    for partition in partitions:\n",
    "        xl, xr = get_coords(df, column_x, partition, indexes, offset=offsets[0])\n",
    "        yl, yr = get_coords(df, column_y, partition, indexes, offset=offsets[1])\n",
    "        rects.append(((xl, yl),(xr, yr)))\n",
    "    return rects\n",
    "\n",
    "def get_bounds(df, column, indexes, offset=1.0):\n",
    "    if column in categorical:\n",
    "        return 0-offset, len(indexes[column])+offset\n",
    "    return df[column].min()-offset, df[column].max()+offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a7db90-d81d-4dac-b3fa-8dc4a7bcbf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the bounding rects of all partitions that we created\n",
    "indexes = build_indexes(df)\n",
    "column_x, column_y = feature_columns[:2]\n",
    "rects = get_partition_rects(df, final_partitions, column_x, column_y, indexes, offsets=[0.0, 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e15834-9803-4721-9799-f6ca02798a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the rectangles\n",
    "def plot_rects(df, ax, rects, column_x, column_y, edgecolor='black', facecolor='none'):\n",
    "    for (xl, yl),(xr, yr) in rects:\n",
    "        ax.add_patch(patches.Rectangle((xl,yl),xr-xl,yr-yl,linewidth=1,edgecolor=edgecolor,facecolor=facecolor, alpha=0.5))\n",
    "    ax.set_xlim(*get_bounds(df, column_x, indexes))\n",
    "    ax.set_ylim(*get_bounds(df, column_y, indexes))\n",
    "    ax.set_xlabel(column_x)\n",
    "    ax.set_ylabel(column_y)\n",
    "\n",
    "pl.figure(figsize=(20,20))\n",
    "ax = pl.subplot(111)\n",
    "plot_rects(df, ax, rects, column_x, column_y, facecolor='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79461f5-5904-4608-b5c3-20ff8ed661f7",
   "metadata": {},
   "source": [
    "### Question 4 (Limitations of k-anonimity) <a id=\"part1sec5\"></a>\n",
    "\n",
    "Beyond the observed limitation above, what are the key limitations of this approach? Explain why the following scenarios stand out as critical issues for $k$-anonimity\n",
    "\n",
    "- All $k$ records in a group share the same sensitive attribute? \n",
    "- An adversary knows $k-1$ individuals in a group with identical quasi-identifiers?\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bf5870-fa37-4afe-b1b1-b363f259839b",
   "metadata": {},
   "source": [
    "\n",
    "## Presenting L-diversity (naive way) <a id=\"part1sec6\"></a>\n",
    "\n",
    "The primary strength of $k$-anonymity lies in its simplicity and intuitive nature (a valuable asset when explaining privacy guarantees to non-experts). However, as we have just seen, the model has critical limitations that undermine its effectiveness in real-world scenarios. On its own, $k$-anonymity fails to deliver robust anonymity guarantees. To address these shortcomings, the model is extended to $l$-diversity, which we will explore next. l-diversity, first introduced in 2007 in [5], ensures that each k-anonymous group contains at least $l$ different values of the sensitive attribute. Therefore, even if an adversary can identify the group of a person they still would not be able to find out the value of that person's sensitive attribute with certainty. To implement l-diversity, we can do the following:\n",
    "\n",
    "- Modify our `is_valid` function to not only check for the size of the partition but also ensure that the values of the sensitive attribute are diverse enough.\n",
    "- Modify the `split` function to produce splits that are diverse (if possible)\n",
    "\n",
    "**Remark:** Here we will only implement the first point to keep things simple, please keep in mind that this is not the smartest way to implement $l$-diversity, as our \"naive\" splitting function might produce invalid splits even when it would actually be possible to produce a valid one.\n",
    "\n",
    "- [5] [l-Diversity: Privacy Beyond k-Anonymity](https://personal.utdallas.edu/~muratk/courses/privacy08f_files/ldiversity.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96788c8d-dc46-4ffb-b69b-d63565765849",
   "metadata": {},
   "source": [
    "### Question 5 (Implementing l-diversity) <a id=\"part1sec7\"></a>\n",
    "\n",
    "Implement a ``is_l_diverse`` function that returns `True` if a given partition contains at least `l` different values of the sensitive attribute, `False` otherwise. Then using the ``partition_dataset`` function, compute a partition that satisfy $l$-diversity for $l=2$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3657f978-a782-4528-b370-43f4e2747deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_l_diverse(df, partition, sensitive_column, l=2):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: \n",
    "        The dataframe for which to check l-diversity\n",
    "    partition: \n",
    "        The partition of the dataframe on which to check l-diversity\n",
    "    sensitive_column: \n",
    "        The name of the sensitive column\n",
    "    l: \n",
    "        The minimum required diversity of sensitive attribute values in the partition\n",
    "        \n",
    "    Returns\n",
    "    ------- \n",
    "    verif: \n",
    "        True if the partition is valid according to our l-diversity criteria, False otherwise.\n",
    "    \"\"\"\n",
    "    # TO COMPLETE\n",
    "    pass # this is just to avoid error while the function is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1766d0-5588-42b8-952d-a545c539e192",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_l_diverse_partitions = partition_dataset(df, feature_columns, sensitive_column, full_spans, [TO COMPLETE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f77975-1350-4e46-8492-6e743ebdce76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the partition\n",
    "column_x, column_y = feature_columns[:2]\n",
    "l_diverse_rects = get_partition_rects(df, final_l_diverse_partitions, column_x, column_y, indexes, offsets=[0.0, 0.0])\n",
    "\n",
    "pl.figure(figsize=(20,20))\n",
    "ax = pl.subplot(111)\n",
    "plot_rects(df, ax, l_diverse_rects, column_x, column_y, edgecolor='b', facecolor='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c83d668-fa3c-45f8-b1df-ba7c6919c8bc",
   "metadata": {},
   "source": [
    "### Question 6 (Limitations of l-diversity) <a id=\"part1sec8\"></a>\n",
    "\n",
    "What are the key limitations of this approach? Can you think of a scenario that would stand as critical for $l$-diversity? \n",
    "\n",
    "**Hint** Even when using l-diversity an adversary could still learn some information about a person's sensitive attribute using probabilistic reasoning or prior knowledge. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e364415-beb3-45a1-b380-0a6846b7ad45",
   "metadata": {},
   "source": [
    "## Presenting T-closeness <a id=\"part1sec9\"></a>\n",
    "\n",
    "t-closeness, also introduced in 2007 in [3], demands that the statistical distribution of the sensitive attribute values in each k-anonymous group is \"close\" to the overall distribution of that attribute in the entire dataset. Typically, assuming the sensitive attribute has $m$ modalities, the closeness between two probability vectors $p=(p_1,...,p_m)$ and $q=(q_1,...,q_m)$ over these modalities can be measured using e.g. the Kullback-Leibler (KL) divergence defined as follows: $$D_{KL}(p,q) = \\sum_{i=1}^{m}p_i \\log(\\frac{p_i}{q_i}).$$\n",
    "\n",
    "If we ensure that between any two paritions the divergence between the sensitive attrivutes within the groups is bounded by some small constant $t$, the adversary could then only learn a limited amount of information from comparing the distribution of the values in the group to the distribution in the entire dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031766cc-d295-46e6-a6b8-1a83f8b20871",
   "metadata": {},
   "source": [
    "### Question 7 (Implementing t-closeness) <a id=\"part1sec10\"></a>\n",
    "\n",
    "Implement a version of the `is_valid` function that returns `True` if the partition is diverse enough and `False` otherwise. To measure diversity, compute the total variation distance (easier to implement compared to KL) between the empirical probability distribution of the sensitive attribute over the entire dataset vs. the distribution over the partition (the total variation distance is the maximum pointwise absolute difference between the two distributions). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb713a7-9eb3-4ac8-9799-a8f7bb5919ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we generate the global frequencies for the sensitive column \n",
    "global_freqs = {}\n",
    "total_count = float(len(df))\n",
    "group_counts = df.groupby(sensitive_column)[sensitive_column].agg('count')\n",
    "for value, count in group_counts.to_dict().items():\n",
    "    p = count/total_count\n",
    "    global_freqs[value] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398b4f52-16a9-4879-94fa-3e6ba83efc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_t_close(df, partition, sensitive_column, global_freqs, t=0.1):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: \n",
    "        The dataframe for which to check t-closeness\n",
    "    partition: \n",
    "        The partition of the dataframe on which to check t-closeness\n",
    "    sensitive_column: \n",
    "        The name of the sensitive column\n",
    "    global_freqs: \n",
    "        The global frequencies of the sensitive attribute values\n",
    "    t: \n",
    "        The maximum allowed distance\n",
    "        \n",
    "    Returns\n",
    "    ------- \n",
    "    verif: \n",
    "        True if the partition is valid according to our t-closeness criteria, False otherwise.\n",
    "    \"\"\"\n",
    "    # TO COMPLETE\n",
    "    pass # this is just to avoid error while the function is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6d3b8d-b64b-413a-9971-4372a4fefa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_t_close_partitions = partition_dataset(df, feature_columns, sensitive_column, full_spans, lambda *args: is_k_anonymous(*args) and is_t_close(*args, global_freqs))\n",
    "\n",
    "column_x, column_y = feature_columns[:2]\n",
    "t_close_rects = get_partition_rects(df, final_t_close_partitions, column_x, column_y, indexes, offsets=[0.0, 0.0])\n",
    "pl.figure(figsize=(20,20))\n",
    "ax = pl.subplot(111)\n",
    "plot_rects(df, ax, t_close_rects, column_x, column_y, edgecolor='b', facecolor='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4073bdb-44f8-48e9-9dd9-c28d1ec3ba20",
   "metadata": {},
   "source": [
    "### Question 8 (Analysis of the usefulness of t-closeness) <a id=\"part1sec11\"></a>\n",
    "\n",
    "Below, we run a partition procedure for $t$-closeness and plot the results. What do you think about the usefulness of this partition ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d3a855-b2a0-4c0e-a890-b2b85643a042",
   "metadata": {},
   "source": [
    "# Part 2: Brittleness of privacy through aggregation (a.k.a. attacking ML models) <a id=\"part2\"></a>\n",
    "\n",
    "Beyond standard privacy definition (such as $k$-anonymity, $l$-diversity, and $t$-closeness, each of which has well-documented limitations), there’s a common but misplaced belief that data integrated into aggregate statistical queries (e.g., during the training of large machine learning models) inherently benefits from a \"hide in the crowd\" effect. Unfortunately, this assumption does not hold in general, as we will demonstrate in the second part of this session. For simplicity, we focus on straightforward cases where \"playing the role of the adversary\" can be executed in just a few minutes. However, it is important to note that, with more time and effort, similar attacks can be extended to extract sensitive information from the training data of even highly complex models (such as large language models) as we discussed in class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9db1ba4-b943-4b21-b990-bbc88bd8d92b",
   "metadata": {},
   "source": [
    "### Another Dataset \n",
    "\n",
    "We will be working with the Pima Indians Diabetes Dataset, a well-known dataset originally collected by the National Institute of Diabetes and Digestive and Kidney Diseases. You can read more about the dataset [here](https://www.openml.org/search?type=data&status=active&id=37&sort=runs). The following line loads the dataset into a pandas DataFrame, preserving the original structure of the attributes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fc2490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data from https://openml.org/search?type=data&status=active&id=37\n",
    "pima = fetch_openml(name='diabetes', version=1, parser='auto')\n",
    "# Convert target to numeric +/- 1\n",
    "outcome = np.where(pima.target == 'tested_positive', 1, -1)\n",
    "n = outcome.size\n",
    "# Standardize the data and add intercept\n",
    "\n",
    "data = np.concatenate((np.ones((n, 1)), StandardScaler().fit_transform(pima.data)), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "MJnn9JtGLsuZ",
   "metadata": {
    "id": "MJnn9JtGLsuZ"
   },
   "source": [
    "### Question 1 (Warm-Up: guessing the target vetcore from aggregated observations) <a id=\"part2sec1\"></a>\n",
    "\n",
    "In this first exercise, we assume that we are an adversary having access to a set of random vectors $z_1, ..., z_K$ that represent the dot product between the label (target) vector $y \\in \\{-1,1\\}^n$ and a set of random vector $w_1, ..., w_K \\in \\mathbb{R}^n$. Assume we the adversary knows the matrix $W=[w_1, ..., w_K]$, how could they guess the value of the target $y$ for the dataset at hand? Can you also guess how the value of $K$ would would influence the quality of your strategy ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cb66f7-2d8b-4173-ba5b-a5e30bca32df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b963d64-240a-4069-8a0f-2b9910beed06",
   "metadata": {},
   "source": [
    "### Question 2 (Warm-Up: verifying the attack) <a id=\"part2sec2\"></a>\n",
    "\n",
    "- Complete the code below with your idea of how to predict the labels $y$ from the observed random dot products $z$\n",
    "- Implement and observe the ROC (Receiver Operating Characteristic) and DET (Detection Error Tradeoff) curves associated with your guess.\n",
    "- By varying $K$, find the minimal value of $K$ that give non trivial recovery performance. For what value of $K$ can you recover 50% of the labels at 5% FPR? \n",
    "- What changes if we now assume that some of the labels in $y$ are known?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febad6c2-3189-4335-9839-f4c34dfdcbc7",
   "metadata": {
    "id": "febad6c2-3189-4335-9839-f4c34dfdcbc7"
   },
   "outputs": [],
   "source": [
    "# Use label mapped to {-1,1}\n",
    "y = outcome\n",
    "n = y.size\n",
    "# Observe K dot products with random sign vectors\n",
    "K = 50\n",
    "# Do it several times to get statistically significant results\n",
    "nMC = 50    # Number of Monte Carlo runs\n",
    "estim = np.zeros((nMC, n))\n",
    "for iMC in range (nMC):\n",
    "    # Observe dot product with random signs matrix\n",
    "    W = np.power(-1, np.random.binomial(1, 0.5, size=(K,n)))\n",
    "    z = np.matmul(W, y)\n",
    "\n",
    "    # Begin TODO: Use a better estimation method!\n",
    "    estim[iMC, :] = np.random.normal(size=(1,n))\n",
    "    # End TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcd01cd",
   "metadata": {},
   "source": [
    "### Question 3 (Model inversion attack on a logistic regression) <a id=\"part2sec3\"></a>\n",
    "\n",
    "In this part, we provide a utility function that can be used to compare two ROC curves on the same plot and examine the result of using logistic regression on this dataset (you can experiment with different train and test splits). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a90112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_two_roc_curves_from_predictions(y_true1, y_score1, label1, y_true2, y_score2, label2):\n",
    "    \"\"\"\n",
    "    Plots two ROC curves from given true labels and predicted scores.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    y_true1 (array-like): \n",
    "        True binary labels for the first set of predictions.\n",
    "    y_score1 (array-like): \n",
    "        Target scores for the first set of predictions.\n",
    "    label1 (str): \n",
    "        Label for the first ROC curve.\n",
    "    y_true2 (array-like): \n",
    "        True binary labels for the second set of predictions.\n",
    "    y_score2 (array-like): \n",
    "        Target scores for the second set of predictions.\n",
    "    label2 (str): \n",
    "        Label for the second ROC curve.\n",
    "    \"\"\"\n",
    "    fpr1, tpr1, tresh = metrics.roc_curve(y_true1, y_score1)\n",
    "    auc1 = metrics.roc_auc_score(y_true1, y_score1)\n",
    "    plt.plot(fpr1, tpr1, label=label1+' (AUC={0:.2f})'.format(auc1))\n",
    "    fpr2, tpr2, tresh = metrics.roc_curve(y_true2, y_score2)\n",
    "    auc2 = metrics.roc_auc_score(y_true2, y_score2)\n",
    "    plt.plot(fpr2, tpr2, label=label2+' (AUC={0:.2f})'.format(auc2))\n",
    "    plt.legend(loc=0)\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d2e364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit logistic regression to the data (without intercept as we explicitly added it to the data already)\n",
    "X = data\n",
    "y = outcome\n",
    "(n, d) = X.shape\n",
    "n_train = 200\n",
    "n_test = n - n_train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=n_train, random_state=45)\n",
    "logreg = LogisticRegression(fit_intercept=False)\n",
    "logreg.fit(X_train, y_train)\n",
    "# Plot training and test performance as ROCs\n",
    "y_train_pred = logreg.predict_proba(X_train)[:,1]\n",
    "y_test_pred = logreg.predict_proba(X_test)[:,1]\n",
    "print('Training and test accuracies: {0:.2f}, {1:.2f}'.format(np.sum(y_train*(y_train_pred-0.5) > 0)/n_train,\n",
    "    np.sum(y_test*(y_test_pred-0.5) > 0)/n_test))\n",
    "display_two_roc_curves_from_predictions(y_train, y_train_pred, 'Training performance',\n",
    "    y_test, y_test_pred, 'Test performance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bc8400",
   "metadata": {},
   "source": [
    "Implement a function to compute the gradients of the logistic loss for each training example in a dataset. These gradients will serve as the foundation for constructing a statistical test designed to infer the value of an unknown label.  The scenario assumes that you are and adversary having access to $K$ known labels, along with their feature matrix and a pre-trained logistic regression model. By analyzing the gradients, you can derive statisticl insights about the unknown label, effectively \"guessing\" its value based on the model’s behavior and the known data points. This approach highlights how gradient information can be exploited to infer sensitive information, even when only partial labels are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c990b525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_gradients(X, y, logreg):\n",
    "     \"\"\"\n",
    "     Compute the gradients of the logistic regression loss function with respect to model parameters.\n",
    "\n",
    "     Parameters:\n",
    "     ----------\n",
    "     X (numpy.ndarray): \n",
    "         The input feature matrix of shape (n, d), where n is the number of samples and d is the number of features.\n",
    "     y (numpy.ndarray): \n",
    "         The target labels of shape (n,), where n is the number of samples.\n",
    "     logreg (object): \n",
    "         A trained logistic regression model.\n",
    "\n",
    "     Returns:\n",
    "     ----------\n",
    "     numpy.ndarray: \n",
    "         The gradient matrix of shape (n, d), where each row corresponds to the gradient for a single sample.\n",
    "     \"\"\"\n",
    "     # TO COMPLETE\n",
    "     pass # this is just to avoid error while the function is empty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc89e3f1-7475-46ba-938f-f3f962c746cb",
   "metadata": {},
   "source": [
    "### Question 4 (Success with respect to side information) <a id=\"part2sec4\"></a>\n",
    "\n",
    "Experimenting with random subsets of the data (using the provided code as example), for what values of $K$ does this approach start to give non trivial recovery performance? Try different values of the training size $n$; how does it modify the previous conclusion? What aspect of the model appears to be important for ensuring the success of the recovery? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d01eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will work on recovering data from the training sample\n",
    "X = X_train\n",
    "y = y_train\n",
    "(n, d) = X.shape\n",
    "# Compute the probabilistic predictions from the model\n",
    "p_hat = logreg.predict_proba(X)[:,1]\n",
    "# Try reconstruction attack assuming K known labels on randomly chosen data subsets\n",
    "K = 50 # Number of known labels\n",
    "# Number of Monte Carlo experiments\n",
    "nMC = 500\n",
    "y_true = np.zeros(nMC)\n",
    "y_guess = np.zeros(nMC)\n",
    "y_pred = np.zeros(nMC)\n",
    "\n",
    "\n",
    "for i in range(nMC):\n",
    "    # Draw a random permutation and try to reconstruct y[ind[0]] assuming knowledge of y[ind[1:p+1]]\n",
    "    ind = np.random.permutation(n)\n",
    "    # True label\n",
    "    y_true[i] = y[ind[0]]\n",
    "    # Model prediction\n",
    "    y_pred[i] = p_hat[ind[0]]\n",
    "    # Begin TODO: Your guess here\n",
    "    y_guess[i] = np.random.normal(size=1)\n",
    "    # End TODO\n",
    "\n",
    "\n",
    "display_two_roc_curves_from_predictions(y_true, y_pred, 'Model prediction',\n",
    "    y_true, y_guess, 'Attack reconstruction')\n",
    "plt.title(\"n={}, K={}\".format(n, K))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
